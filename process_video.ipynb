{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T06:24:54.411004Z",
     "start_time": "2019-02-08T06:24:53.815692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"process_video.py\", line 3, in <module>\r\n",
      "    from visualize_cv2 import model, display_instances, class_names\r\n",
      "  File \"/Volumes/G-DRIVE/cloud2019/Mask-RCNN-series/visualize_cv2.py\", line 5, in <module>\r\n",
      "    import coco\r\n",
      "ModuleNotFoundError: No module named 'coco'\r\n"
     ]
    }
   ],
   "source": [
    "!python process_video.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T13:26:41.617229Z",
     "start_time": "2019-02-08T13:23:11.865967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                93\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "WARNING:tensorflow:From /Users/aadebuger/GEXT/maskrcnnvenv3/lib/python3.6/site-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "2019-02-08 21:23:21.741844: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"process_video.py\", line 17, in <module>\n",
      "    results = model.detect([frame], verbose=0)\n",
      "  File \"/Volumes/G-DRIVE/cloud2019/Mask-RCNN-series/model.py\", line 2525, in detect\n"
     ]
    }
   ],
   "source": [
    "!python process_video.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T13:35:06.989760Z",
     "start_time": "2019-02-08T13:30:50.232434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                93\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "WARNING:tensorflow:From /Users/aadebuger/GEXT/maskrcnnvenv3/lib/python3.6/site-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "2019-02-08 21:31:02.013018: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 926 y1= 89 x2= 960 y2= 199\n",
      "Traceback (most recent call last):\n",
      "  File \"process_video.py\", line 20, in <module>\n",
      "    frame, r['rois'], r['masks'], r['class_ids'], class_names, r['scores']\n",
      "  File \"/Volumes/G-DRIVE/cloud2019/Mask-RCNN-series/visualize_cv2.py\", line 98, in display_instances\n",
      "    totempimage(image,mask,color)\n",
      "  File \"/Volumes/G-DRIVE/cloud2019/Mask-RCNN-series/visualize_cv2.py\", line 62, in totempimage\n",
      "    cv2.imwrite(\"temp{0}.jpg\".format(serialid),rectangle)\n",
      "UnboundLocalError: local variable 'serialid' referenced before assignment\n"
     ]
    }
   ],
   "source": [
    "!python process_video.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T13:48:35.342413Z",
     "start_time": "2019-02-08T13:38:09.790508Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                93\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "WARNING:tensorflow:From /Users/aadebuger/GEXT/maskrcnnvenv3/lib/python3.6/site-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "2019-02-08 21:38:19.850965: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 926 y1= 89 x2= 960 y2= 199\n",
      "x1= 922 y1= 91 x2= 959 y2= 214\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 881 y1= 108 x2= 960 y2= 311\n",
      "x1= 877 y1= 110 x2= 960 y2= 317\n",
      "x1= 873 y1= 107 x2= 960 y2= 320\n",
      "x1= 867 y1= 107 x2= 960 y2= 321\n",
      "x1= 868 y1= 109 x2= 960 y2= 324\n",
      "x1= 866 y1= 108 x2= 960 y2= 324\n",
      "x1= 865 y1= 108 x2= 960 y2= 324\n",
      "x1= 863 y1= 108 x2= 960 y2= 326\n",
      "x1= 863 y1= 108 x2= 960 y2= 329\n",
      "x1= 860 y1= 107 x2= 960 y2= 329\n",
      "x1= 858 y1= 109 x2= 960 y2= 329\n",
      "x1= 856 y1= 110 x2= 960 y2= 329\n",
      "x1= 853 y1= 110 x2= 960 y2= 330\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 849 y1= 105 x2= 960 y2= 329\n",
      "x1= 847 y1= 100 x2= 960 y2= 330\n",
      "x1= 847 y1= 101 x2= 960 y2= 332\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 844 y1= 100 x2= 960 y2= 322\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python process_video.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T13:52:56.581667Z",
     "start_time": "2019-02-08T13:48:49.314579Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                93\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "WARNING:tensorflow:From /Users/aadebuger/GEXT/maskrcnnvenv3/lib/python3.6/site-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "2019-02-08 21:48:58.478663: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 926 y1= 89 x2= 960 y2= 199\n",
      "Traceback (most recent call last):\n",
      "  File \"process_video.py\", line 20, in <module>\n",
      "    frame, r['rois'], r['masks'], r['class_ids'], class_names, r['scores']\n",
      "  File \"/Volumes/G-DRIVE/cloud2019/Mask-RCNN-series/visualize_cv2.py\", line 106, in display_instances\n",
      "    totempimage(image,mask,color)\n",
      "  File \"/Volumes/G-DRIVE/cloud2019/Mask-RCNN-series/visualize_cv2.py\", line 66, in totempimage\n",
      "    image[:, :, n] * (1 - alpha) + alpha * c,\n",
      "IndexError: too many indices for array\n"
     ]
    }
   ],
   "source": [
    "!python process_video.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T14:28:23.131616Z",
     "start_time": "2019-02-08T14:09:22.766845Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                93\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "WARNING:tensorflow:From /Users/aadebuger/GEXT/maskrcnnvenv3/lib/python3.6/site-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "2019-02-08 22:09:32.828171: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 926 y1= 89 x2= 960 y2= 199\n",
      "x1= 922 y1= 91 x2= 959 y2= 214\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 881 y1= 108 x2= 960 y2= 311\n",
      "x1= 877 y1= 110 x2= 960 y2= 317\n",
      "x1= 873 y1= 107 x2= 960 y2= 320\n",
      "x1= 867 y1= 107 x2= 960 y2= 321\n",
      "x1= 868 y1= 109 x2= 960 y2= 324\n",
      "x1= 866 y1= 108 x2= 960 y2= 324\n",
      "x1= 865 y1= 108 x2= 960 y2= 324\n",
      "x1= 863 y1= 108 x2= 960 y2= 326\n",
      "x1= 863 y1= 108 x2= 960 y2= 329\n",
      "x1= 860 y1= 107 x2= 960 y2= 329\n",
      "x1= 858 y1= 109 x2= 960 y2= 329\n",
      "x1= 856 y1= 110 x2= 960 y2= 329\n",
      "x1= 853 y1= 110 x2= 960 y2= 330\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 849 y1= 105 x2= 960 y2= 329\n",
      "x1= 847 y1= 100 x2= 960 y2= 330\n",
      "x1= 847 y1= 101 x2= 960 y2= 332\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 844 y1= 100 x2= 960 y2= 322\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 817 y1= 88 x2= 960 y2= 339\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python process_video.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T14:40:45.473477Z",
     "start_time": "2019-02-08T14:28:27.333808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                93\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "WARNING:tensorflow:From /Users/aadebuger/GEXT/maskrcnnvenv3/lib/python3.6/site-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "2019-02-08 22:28:36.362085: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 926 y1= 89 x2= 960 y2= 199\n",
      "x1= 922 y1= 91 x2= 959 y2= 214\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 881 y1= 108 x2= 960 y2= 311\n",
      "x1= 877 y1= 110 x2= 960 y2= 317\n",
      "x1= 873 y1= 107 x2= 960 y2= 320\n",
      "x1= 867 y1= 107 x2= 960 y2= 321\n",
      "x1= 868 y1= 109 x2= 960 y2= 324\n",
      "x1= 866 y1= 108 x2= 960 y2= 324\n",
      "x1= 865 y1= 108 x2= 960 y2= 324\n",
      "x1= 863 y1= 108 x2= 960 y2= 326\n",
      "x1= 863 y1= 108 x2= 960 y2= 329\n",
      "x1= 860 y1= 107 x2= 960 y2= 329\n",
      "x1= 858 y1= 109 x2= 960 y2= 329\n",
      "x1= 856 y1= 110 x2= 960 y2= 329\n",
      "x1= 853 y1= 110 x2= 960 y2= 330\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 849 y1= 105 x2= 960 y2= 329\n",
      "x1= 847 y1= 100 x2= 960 y2= 330\n",
      "x1= 847 y1= 101 x2= 960 y2= 332\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 844 y1= 100 x2= 960 y2= 322\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 817 y1= 88 x2= 960 y2= 339\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python process_video.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T15:48:22.900719Z",
     "start_time": "2019-02-08T14:40:53.289213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                93\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "WARNING:tensorflow:From /Users/aadebuger/GEXT/maskrcnnvenv3/lib/python3.6/site-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "2019-02-08 22:41:02.526551: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 926 y1= 89 x2= 960 y2= 199\n",
      "x1= 922 y1= 91 x2= 959 y2= 214\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 881 y1= 108 x2= 960 y2= 311\n",
      "x1= 877 y1= 110 x2= 960 y2= 317\n",
      "x1= 873 y1= 107 x2= 960 y2= 320\n",
      "x1= 867 y1= 107 x2= 960 y2= 321\n",
      "x1= 868 y1= 109 x2= 960 y2= 324\n",
      "x1= 866 y1= 108 x2= 960 y2= 324\n",
      "x1= 865 y1= 108 x2= 960 y2= 324\n",
      "x1= 863 y1= 108 x2= 960 y2= 326\n",
      "x1= 863 y1= 108 x2= 960 y2= 329\n",
      "x1= 860 y1= 107 x2= 960 y2= 329\n",
      "x1= 858 y1= 109 x2= 960 y2= 329\n",
      "x1= 856 y1= 110 x2= 960 y2= 329\n",
      "x1= 853 y1= 110 x2= 960 y2= 330\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 849 y1= 105 x2= 960 y2= 329\n",
      "x1= 847 y1= 100 x2= 960 y2= 330\n",
      "x1= 847 y1= 101 x2= 960 y2= 332\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 844 y1= 100 x2= 960 y2= 322\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 817 y1= 88 x2= 960 y2= 339\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 707 y1= 38 x2= 960 y2= 324\n",
      "x1= 710 y1= 35 x2= 960 y2= 330\n",
      "x1= 695 y1= 36 x2= 960 y2= 335\n",
      "x1= 693 y1= 37 x2= 960 y2= 337\n",
      "x1= 694 y1= 33 x2= 960 y2= 333\n",
      "x1= 699 y1= 38 x2= 960 y2= 329\n",
      "x1= 696 y1= 40 x2= 960 y2= 320\n",
      "x1= 692 y1= 40 x2= 960 y2= 323\n",
      "x1= 688 y1= 35 x2= 960 y2= 332\n",
      "x1= 682 y1= 36 x2= 960 y2= 330\n",
      "x1= 678 y1= 37 x2= 958 y2= 340\n",
      "x1= 684 y1= 35 x2= 960 y2= 332\n",
      "x1= 700 y1= 32 x2= 960 y2= 329\n",
      "x1= 674 y1= 38 x2= 959 y2= 335\n",
      "x1= 675 y1= 38 x2= 956 y2= 337\n",
      "x1= 671 y1= 38 x2= 960 y2= 334\n",
      "x1= 672 y1= 37 x2= 956 y2= 340\n",
      "x1= 670 y1= 38 x2= 954 y2= 339\n",
      "x1= 668 y1= 38 x2= 954 y2= 340\n",
      "x1= 665 y1= 37 x2= 956 y2= 340\n",
      "x1= 664 y1= 37 x2= 958 y2= 342\n",
      "x1= 661 y1= 38 x2= 956 y2= 341\n",
      "x1= 661 y1= 36 x2= 954 y2= 341\n",
      "x1= 660 y1= 40 x2= 960 y2= 337\n",
      "x1= 660 y1= 38 x2= 951 y2= 342\n",
      "x1= 658 y1= 39 x2= 960 y2= 334\n",
      "x1= 656 y1= 39 x2= 953 y2= 342\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 650 y1= 38 x2= 952 y2= 342\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 641 y1= 33 x2= 952 y2= 345\n",
      "x1= 640 y1= 35 x2= 950 y2= 341\n",
      "x1= 639 y1= 35 x2= 954 y2= 342\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 645 y1= 29 x2= 954 y2= 344\n",
      "x1= 641 y1= 27 x2= 952 y2= 343\n",
      "x1= 634 y1= 30 x2= 944 y2= 346\n",
      "x1= 632 y1= 31 x2= 943 y2= 347\n",
      "x1= 630 y1= 31 x2= 942 y2= 347\n",
      "x1= 636 y1= 30 x2= 945 y2= 341\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 629 y1= 28 x2= 938 y2= 343\n",
      "x1= 628 y1= 26 x2= 938 y2= 343\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 590 y1= 30 x2= 902 y2= 342\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 530 y1= 35 x2= 849 y2= 329\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 515 y1= 42 x2= 832 y2= 330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO INSTANCES TO DISPLAY\n",
      "x1= 505 y1= 45 x2= 823 y2= 325\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 362 y1= 47 x2= 691 y2= 328\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 340 y1= 53 x2= 663 y2= 328\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 335 y1= 44 x2= 660 y2= 334\n",
      "x1= 324 y1= 52 x2= 659 y2= 327\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 94 y1= 4 x2= 137 y2= 15\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 328 y1= 59 x2= 649 y2= 337\n",
      "x1= 316 y1= 59 x2= 644 y2= 335\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 321 y1= 56 x2= 640 y2= 337\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 313 y1= 48 x2= 637 y2= 345\n",
      "x1= 311 y1= 47 x2= 635 y2= 344\n",
      "x1= 95 y1= 5 x2= 134 y2= 15\n",
      "x1= 95 y1= 5 x2= 134 y2= 15\n",
      "x1= 310 y1= 47 x2= 634 y2= 340\n",
      "x1= 308 y1= 45 x2= 630 y2= 339\n",
      "x1= 305 y1= 44 x2= 628 y2= 336\n",
      "x1= 297 y1= 53 x2= 625 y2= 331\n",
      "x1= 300 y1= 47 x2= 625 y2= 336\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 283 y1= 53 x2= 619 y2= 331\n",
      "x1= 283 y1= 52 x2= 615 y2= 327\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 286 y1= 44 x2= 611 y2= 340\n",
      "x1= 280 y1= 45 x2= 609 y2= 335\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 275 y1= 43 x2= 603 y2= 333\n",
      "x1= 273 y1= 44 x2= 602 y2= 333\n",
      "x1= 270 y1= 45 x2= 597 y2= 332\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 263 y1= 45 x2= 587 y2= 335\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 257 y1= 43 x2= 580 y2= 335\n",
      "x1= 258 y1= 46 x2= 583 y2= 335\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 245 y1= 45 x2= 572 y2= 339\n",
      "x1= 243 y1= 45 x2= 570 y2= 339\n",
      "x1= 239 y1= 54 x2= 568 y2= 331\n",
      "x1= 228 y1= 52 x2= 565 y2= 333\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 230 y1= 44 x2= 557 y2= 337\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 224 y1= 43 x2= 552 y2= 339\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 221 y1= 48 x2= 549 y2= 338\n",
      "x1= 219 y1= 47 x2= 547 y2= 336\n",
      "x1= 216 y1= 45 x2= 547 y2= 334\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"process_video.py\", line 17, in <module>\n",
      "    results = model.detect([frame], verbose=0)\n",
      "  File \"/Volumes/G-DRIVE/cloud2019/Mask-RCNN-series/model.py\", line 2504, in detect\n",
      "    molded_images, image_metas, windows = self.mold_inputs(images)\n",
      "  File \"/Volumes/G-DRIVE/cloud2019/Mask-RCNN-series/model.py\", line 2402, in mold_inputs\n",
      "    mode=self.config.IMAGE_RESIZE_MODE)\n",
      "  File \"/Users/aadebuger/GEXT/maskrcnnvenv3/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg/mrcnn/utils.py\", line 457, in resize_image\n",
      "    image = np.pad(image, padding, mode='constant', constant_values=0)\n",
      "  File \"/Users/aadebuger/GEXT/maskrcnnvenv3/lib/python3.6/site-packages/numpy/lib/arraypad.py\", line 1247, in pad\n",
      "    newmat = _append_const(newmat, pad_after, after_val, axis)\n",
      "  File \"/Users/aadebuger/GEXT/maskrcnnvenv3/lib/python3.6/site-packages/numpy/lib/arraypad.py\", line 162, in _append_const\n",
      "    return _do_append(arr, np.full(padshape, val, dtype=arr.dtype), axis)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python process_video.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T06:53:38.808614Z",
     "start_time": "2019-02-09T06:53:38.131803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"process_video.py\", line 3, in <module>\r\n",
      "    from visualize_cv2 import model, display_instances, class_names\r\n",
      "  File \"/Volumes/G-DRIVE/cloud2019/Mask-RCNN-series/visualize_cv2.py\", line 75\r\n",
      "    def torect(filename,serialid)\r\n",
      "                                ^\r\n",
      "SyntaxError: invalid syntax\r\n"
     ]
    }
   ],
   "source": [
    "!python process_video.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T06:58:13.321618Z",
     "start_time": "2019-02-09T06:53:57.283244Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                93\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "WARNING:tensorflow:From /Users/aadebuger/GEXT/maskrcnnvenv3/lib/python3.6/site-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "2019-02-09 14:54:07.802796: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 926 y1= 89 x2= 960 y2= 199\n",
      "Traceback (most recent call last):\n",
      "  File \"process_video.py\", line 20, in <module>\n",
      "    frame, r['rois'], r['masks'], r['class_ids'], class_names, r['scores']\n",
      "  File \"/Volumes/G-DRIVE/cloud2019/Mask-RCNN-series/visualize_cv2.py\", line 120, in display_instances\n",
      "    totempimage(image,mask,color)\n",
      "  File \"/Volumes/G-DRIVE/cloud2019/Mask-RCNN-series/visualize_cv2.py\", line 73, in totempimage\n",
      "    torect(\"temp{0}.jpg\".format(serialid),serialid)\n",
      "  File \"/Volumes/G-DRIVE/cloud2019/Mask-RCNN-series/visualize_cv2.py\", line 81, in torect\n",
      "    binary,contours, hierarchy = cv2.findContours(binary,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
      "ValueError: not enough values to unpack (expected 3, got 2)\n"
     ]
    }
   ],
   "source": [
    "!python process_video.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-09T07:06:48.503Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                93\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "WARNING:tensorflow:From /Users/aadebuger/GEXT/maskrcnnvenv3/lib/python3.6/site-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "2019-02-09 15:06:58.492710: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 926 y1= 89 x2= 960 y2= 199\n",
      "x1= 922 y1= 91 x2= 959 y2= 214\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 881 y1= 108 x2= 960 y2= 311\n",
      "x1= 877 y1= 110 x2= 960 y2= 317\n",
      "x1= 873 y1= 107 x2= 960 y2= 320\n",
      "x1= 867 y1= 107 x2= 960 y2= 321\n"
     ]
    }
   ],
   "source": [
    "!python process_video.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T07:23:56.676964Z",
     "start_time": "2019-02-09T07:17:39.686866Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                93\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "WARNING:tensorflow:From /Users/aadebuger/GEXT/maskrcnnvenv3/lib/python3.6/site-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "2019-02-09 15:17:53.305513: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 926 y1= 89 x2= 960 y2= 199\n",
      "x1= 922 y1= 91 x2= 959 y2= 214\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 881 y1= 108 x2= 960 y2= 311\n",
      "x1= 877 y1= 110 x2= 960 y2= 317\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python process_video.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T07:28:13.198813Z",
     "start_time": "2019-02-09T07:24:02.844959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                93\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "WARNING:tensorflow:From /Users/aadebuger/GEXT/maskrcnnvenv3/lib/python3.6/site-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "2019-02-09 15:24:13.975497: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 926 y1= 89 x2= 960 y2= 199\n",
      "Traceback (most recent call last):\n",
      "  File \"process_video.py\", line 20, in <module>\n",
      "    frame, r['rois'], r['masks'], r['class_ids'], class_names, r['scores']\n",
      "  File \"/Volumes/G-DRIVE/cloud2019/Mask-RCNN-series/visualize_cv2.py\", line 122, in display_instances\n",
      "    totempimage(image,mask,color)\n",
      "  File \"/Volumes/G-DRIVE/cloud2019/Mask-RCNN-series/visualize_cv2.py\", line 74, in totempimage\n",
      "    torect(\"temp{0}.jpg\".format(serialid),serialid)\n",
      "  File \"/Volumes/G-DRIVE/cloud2019/Mask-RCNN-series/visualize_cv2.py\", line 83, in torect\n",
      "    print(\"contours=\",len(coontours))\n",
      "NameError: name 'coontours' is not defined\n"
     ]
    }
   ],
   "source": [
    "!python process_video.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T07:35:02.807628Z",
     "start_time": "2019-02-09T07:29:52.278132Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                93\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "WARNING:tensorflow:From /Users/aadebuger/GEXT/maskrcnnvenv3/lib/python3.6/site-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "2019-02-09 15:30:01.233100: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 926 y1= 89 x2= 960 y2= 199\n",
      "contours= 2\n",
      "x1= 922 y1= 91 x2= 959 y2= 214\n",
      "contours= 2\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python process_video.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T08:13:56.073062Z",
     "start_time": "2019-02-09T07:35:09.539135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                93\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "WARNING:tensorflow:From /Users/aadebuger/GEXT/maskrcnnvenv3/lib/python3.6/site-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "2019-02-09 15:35:21.902641: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 926 y1= 89 x2= 960 y2= 199\n",
      "contours= 2\n",
      "x1= 922 y1= 91 x2= 959 y2= 214\n",
      "contours= 2\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 881 y1= 108 x2= 960 y2= 311\n",
      "contours= 2\n",
      "x1= 877 y1= 110 x2= 960 y2= 317\n",
      "contours= 1\n",
      "x1= 873 y1= 107 x2= 960 y2= 320\n",
      "contours= 3\n",
      "x1= 867 y1= 107 x2= 960 y2= 321\n",
      "contours= 3\n",
      "x1= 868 y1= 109 x2= 960 y2= 324\n",
      "contours= 4\n",
      "x1= 866 y1= 108 x2= 960 y2= 324\n",
      "contours= 3\n",
      "x1= 865 y1= 108 x2= 960 y2= 324\n",
      "contours= 2\n",
      "x1= 863 y1= 108 x2= 960 y2= 326\n",
      "contours= 2\n",
      "x1= 863 y1= 108 x2= 960 y2= 329\n",
      "contours= 2\n",
      "x1= 860 y1= 107 x2= 960 y2= 329\n",
      "contours= 2\n",
      "x1= 858 y1= 109 x2= 960 y2= 329\n",
      "contours= 1\n",
      "x1= 856 y1= 110 x2= 960 y2= 329\n",
      "contours= 1\n",
      "x1= 853 y1= 110 x2= 960 y2= 330\n",
      "contours= 1\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 849 y1= 105 x2= 960 y2= 329\n",
      "contours= 1\n",
      "x1= 847 y1= 100 x2= 960 y2= 330\n",
      "contours= 1\n",
      "x1= 847 y1= 101 x2= 960 y2= 332\n",
      "contours= 1\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 844 y1= 100 x2= 960 y2= 322\n",
      "contours= 1\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 817 y1= 88 x2= 960 y2= 339\n",
      "contours= 1\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 707 y1= 38 x2= 960 y2= 324\n",
      "contours= 2\n",
      "x1= 710 y1= 35 x2= 960 y2= 330\n",
      "contours= 2\n",
      "x1= 695 y1= 36 x2= 960 y2= 335\n",
      "contours= 2\n",
      "x1= 693 y1= 37 x2= 960 y2= 337\n",
      "contours= 2\n",
      "x1= 694 y1= 33 x2= 960 y2= 333\n",
      "contours= 2\n",
      "x1= 699 y1= 38 x2= 960 y2= 329\n",
      "contours= 2\n",
      "x1= 696 y1= 40 x2= 960 y2= 320\n",
      "contours= 2\n",
      "x1= 692 y1= 40 x2= 960 y2= 323\n",
      "contours= 2\n",
      "x1= 688 y1= 35 x2= 960 y2= 332\n",
      "contours= 2\n",
      "x1= 682 y1= 36 x2= 960 y2= 330\n",
      "contours= 2\n",
      "x1= 678 y1= 37 x2= 958 y2= 340\n",
      "contours= 2\n",
      "x1= 684 y1= 35 x2= 960 y2= 332\n",
      "contours= 2\n",
      "x1= 700 y1= 32 x2= 960 y2= 329\n",
      "contours= 2\n",
      "x1= 674 y1= 38 x2= 959 y2= 335\n",
      "contours= 2\n",
      "x1= 675 y1= 38 x2= 956 y2= 337\n",
      "contours= 2\n",
      "x1= 671 y1= 38 x2= 960 y2= 334\n",
      "contours= 2\n",
      "x1= 672 y1= 37 x2= 956 y2= 340\n",
      "contours= 2\n",
      "x1= 670 y1= 38 x2= 954 y2= 339\n",
      "contours= 2\n",
      "x1= 668 y1= 38 x2= 954 y2= 340\n",
      "contours= 2\n",
      "x1= 665 y1= 37 x2= 956 y2= 340\n",
      "contours= 2\n",
      "x1= 664 y1= 37 x2= 958 y2= 342\n",
      "contours= 2\n",
      "x1= 661 y1= 38 x2= 956 y2= 341\n",
      "contours= 2\n",
      "x1= 661 y1= 36 x2= 954 y2= 341\n",
      "contours= 2\n",
      "x1= 660 y1= 40 x2= 960 y2= 337\n",
      "contours= 2\n",
      "x1= 660 y1= 38 x2= 951 y2= 342\n",
      "contours= 2\n",
      "x1= 658 y1= 39 x2= 960 y2= 334\n",
      "contours= 2\n",
      "x1= 656 y1= 39 x2= 953 y2= 342\n",
      "contours= 2\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 650 y1= 38 x2= 952 y2= 342\n",
      "contours= 2\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 641 y1= 33 x2= 952 y2= 345\n",
      "contours= 2\n",
      "x1= 640 y1= 35 x2= 950 y2= 341\n",
      "contours= 2\n",
      "x1= 639 y1= 35 x2= 954 y2= 342\n",
      "contours= 2\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 645 y1= 29 x2= 954 y2= 344\n",
      "contours= 2\n",
      "x1= 641 y1= 27 x2= 952 y2= 343\n",
      "contours= 2\n",
      "x1= 634 y1= 30 x2= 944 y2= 346\n",
      "contours= 2\n",
      "x1= 632 y1= 31 x2= 943 y2= 347\n",
      "contours= 2\n",
      "x1= 630 y1= 31 x2= 942 y2= 347\n",
      "contours= 2\n",
      "x1= 636 y1= 30 x2= 945 y2= 341\n",
      "contours= 2\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 629 y1= 28 x2= 938 y2= 343\n",
      "contours= 2\n",
      "x1= 628 y1= 26 x2= 938 y2= 343\n",
      "contours= 2\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 590 y1= 30 x2= 902 y2= 342\n",
      "contours= 2\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python process_video.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T08:18:06.336759Z",
     "start_time": "2019-02-09T08:14:00.266979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                93\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "WARNING:tensorflow:From /Users/aadebuger/GEXT/maskrcnnvenv3/lib/python3.6/site-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "2019-02-09 16:14:09.479569: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 926 y1= 89 x2= 960 y2= 199\n",
      "contours= 2\n",
      "Traceback (most recent call last):\n",
      "  File \"process_video.py\", line 20, in <module>\n",
      "    frame, r['rois'], r['masks'], r['class_ids'], class_names, r['scores']\n",
      "  File \"/Volumes/G-DRIVE/cloud2019/Mask-RCNN-series/visualize_cv2.py\", line 132, in display_instances\n",
      "    totempimage(image,mask,color)\n",
      "  File \"/Volumes/G-DRIVE/cloud2019/Mask-RCNN-series/visualize_cv2.py\", line 74, in totempimage\n",
      "    torect(\"temp{0}.jpg\".format(serialid),serialid)\n",
      "  File \"/Volumes/G-DRIVE/cloud2019/Mask-RCNN-series/visualize_cv2.py\", line 85, in torect\n",
      "    if len(countours)==2:\n",
      "NameError: name 'countours' is not defined\n"
     ]
    }
   ],
   "source": [
    "!python process_video.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T08:30:55.464180Z",
     "start_time": "2019-02-09T08:19:39.778083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                93\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "WARNING:tensorflow:From /Users/aadebuger/GEXT/maskrcnnvenv3/lib/python3.6/site-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "2019-02-09 16:19:48.678417: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 926 y1= 89 x2= 960 y2= 199\n",
      "contours= 2\n",
      "rect= ((479.5, 271.5), (543.0, 959.0), -90.0)\n",
      "[[959 543]\n",
      " [  0 543]\n",
      " [  0   0]\n",
      " [959   0]]\n",
      "x1= 922 y1= 91 x2= 959 y2= 214\n",
      "contours= 2\n",
      "rect= ((940.5, 153.5), (37.0, 117.0), -0.0)\n",
      "[[922 212]\n",
      " [922  95]\n",
      " [959  95]\n",
      " [959 212]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 881 y1= 108 x2= 960 y2= 311\n",
      "contours= 2\n",
      "rect= ((479.5, 271.5), (543.0, 959.0), -90.0)\n",
      "[[959 543]\n",
      " [  0 543]\n",
      " [  0   0]\n",
      " [959   0]]\n",
      "x1= 877 y1= 110 x2= 960 y2= 317\n",
      "contours= 1\n",
      "x1= 873 y1= 107 x2= 960 y2= 320\n",
      "contours= 3\n",
      "x1= 867 y1= 107 x2= 960 y2= 321\n",
      "contours= 3\n",
      "x1= 868 y1= 109 x2= 960 y2= 324\n",
      "contours= 4\n",
      "x1= 866 y1= 108 x2= 960 y2= 324\n",
      "contours= 3\n",
      "x1= 865 y1= 108 x2= 960 y2= 324\n",
      "contours= 2\n",
      "rect= ((479.5, 271.5), (543.0, 959.0), -90.0)\n",
      "[[959 543]\n",
      " [  0 543]\n",
      " [  0   0]\n",
      " [959   0]]\n",
      "x1= 863 y1= 108 x2= 960 y2= 326\n",
      "contours= 2\n",
      "rect= ((479.5, 271.5), (543.0, 959.0), -90.0)\n",
      "[[959 543]\n",
      " [  0 543]\n",
      " [  0   0]\n",
      " [959   0]]\n",
      "x1= 863 y1= 108 x2= 960 y2= 329\n",
      "contours= 2\n",
      "rect= ((479.5, 271.5), (543.0, 959.0), -90.0)\n",
      "[[959 543]\n",
      " [  0 543]\n",
      " [  0   0]\n",
      " [959   0]]\n",
      "x1= 860 y1= 107 x2= 960 y2= 329\n",
      "contours= 2\n",
      "rect= ((479.5, 271.5), (543.0, 959.0), -90.0)\n",
      "[[959 543]\n",
      " [  0 543]\n",
      " [  0   0]\n",
      " [959   0]]\n",
      "x1= 858 y1= 109 x2= 960 y2= 329\n",
      "contours= 1\n",
      "x1= 856 y1= 110 x2= 960 y2= 329\n",
      "contours= 1\n",
      "x1= 853 y1= 110 x2= 960 y2= 330\n",
      "contours= 1\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 849 y1= 105 x2= 960 y2= 329\n",
      "contours= 1\n",
      "x1= 847 y1= 100 x2= 960 y2= 330\n",
      "contours= 1\n",
      "x1= 847 y1= 101 x2= 960 y2= 332\n",
      "contours= 1\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 844 y1= 100 x2= 960 y2= 322\n",
      "contours= 1\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python process_video.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T09:32:25.676333Z",
     "start_time": "2019-02-09T08:31:01.267492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                93\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "WARNING:tensorflow:From /Users/aadebuger/GEXT/maskrcnnvenv3/lib/python3.6/site-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "2019-02-09 16:31:10.642131: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 926 y1= 89 x2= 960 y2= 199\n",
      "serialid= 0\n",
      "contours= 2\n",
      "rect= ((479.5, 271.5), (543.0, 959.0), -90.0)\n",
      "[[959 543]\n",
      " [  0 543]\n",
      " [  0   0]\n",
      " [959   0]]\n",
      "x1= 922 y1= 91 x2= 959 y2= 214\n",
      "serialid= 1\n",
      "contours= 2\n",
      "rect= ((940.5, 153.5), (37.0, 117.0), -0.0)\n",
      "[[922 212]\n",
      " [922  95]\n",
      " [959  95]\n",
      " [959 212]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 881 y1= 108 x2= 960 y2= 311\n",
      "serialid= 2\n",
      "contours= 2\n",
      "rect= ((479.5, 271.5), (543.0, 959.0), -90.0)\n",
      "[[959 543]\n",
      " [  0 543]\n",
      " [  0   0]\n",
      " [959   0]]\n",
      "x1= 877 y1= 110 x2= 960 y2= 317\n",
      "serialid= 3\n",
      "contours= 1\n",
      "x1= 873 y1= 107 x2= 960 y2= 320\n",
      "serialid= 4\n",
      "contours= 3\n",
      "x1= 867 y1= 107 x2= 960 y2= 321\n",
      "serialid= 5\n",
      "contours= 3\n",
      "x1= 868 y1= 109 x2= 960 y2= 324\n",
      "serialid= 6\n",
      "contours= 4\n",
      "x1= 866 y1= 108 x2= 960 y2= 324\n",
      "serialid= 7\n",
      "contours= 3\n",
      "x1= 865 y1= 108 x2= 960 y2= 324\n",
      "serialid= 8\n",
      "contours= 2\n",
      "rect= ((479.5, 271.5), (543.0, 959.0), -90.0)\n",
      "[[959 543]\n",
      " [  0 543]\n",
      " [  0   0]\n",
      " [959   0]]\n",
      "x1= 863 y1= 108 x2= 960 y2= 326\n",
      "serialid= 9\n",
      "contours= 2\n",
      "rect= ((479.5, 271.5), (543.0, 959.0), -90.0)\n",
      "[[959 543]\n",
      " [  0 543]\n",
      " [  0   0]\n",
      " [959   0]]\n",
      "x1= 863 y1= 108 x2= 960 y2= 329\n",
      "serialid= 10\n",
      "contours= 2\n",
      "rect= ((479.5, 271.5), (543.0, 959.0), -90.0)\n",
      "[[959 543]\n",
      " [  0 543]\n",
      " [  0   0]\n",
      " [959   0]]\n",
      "x1= 860 y1= 107 x2= 960 y2= 329\n",
      "serialid= 11\n",
      "contours= 2\n",
      "rect= ((479.5, 271.5), (543.0, 959.0), -90.0)\n",
      "[[959 543]\n",
      " [  0 543]\n",
      " [  0   0]\n",
      " [959   0]]\n",
      "x1= 858 y1= 109 x2= 960 y2= 329\n",
      "serialid= 12\n",
      "contours= 1\n",
      "x1= 856 y1= 110 x2= 960 y2= 329\n",
      "serialid= 13\n",
      "contours= 1\n",
      "x1= 853 y1= 110 x2= 960 y2= 330\n",
      "serialid= 14\n",
      "contours= 1\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 849 y1= 105 x2= 960 y2= 329\n",
      "serialid= 15\n",
      "contours= 1\n",
      "x1= 847 y1= 100 x2= 960 y2= 330\n",
      "serialid= 16\n",
      "contours= 1\n",
      "x1= 847 y1= 101 x2= 960 y2= 332\n",
      "serialid= 17\n",
      "contours= 1\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 844 y1= 100 x2= 960 y2= 322\n",
      "serialid= 18\n",
      "contours= 1\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 817 y1= 88 x2= 960 y2= 339\n",
      "serialid= 19\n",
      "contours= 1\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 707 y1= 38 x2= 960 y2= 324\n",
      "serialid= 20\n",
      "contours= 2\n",
      "rect= ((873.1661376953125, 184.27438354492188), (262.08538818359375, 218.52110290527344), -30.234573364257812)\n",
      "[[ 814  344]\n",
      " [ 704  155]\n",
      " [ 931   23]\n",
      " [1041  212]]\n",
      "x1= 710 y1= 35 x2= 960 y2= 330\n",
      "serialid= 21\n",
      "contours= 2\n",
      "rect= ((870.7179565429688, 184.30130004882812), (262.8225402832031, 217.86746215820312), -30.361719131469727)\n",
      "[[ 812  344]\n",
      " [ 702  156]\n",
      " [ 929   23]\n",
      " [1039  211]]\n",
      "x1= 695 y1= 36 x2= 960 y2= 335\n",
      "serialid= 22\n",
      "contours= 2\n",
      "rect= ((867.392822265625, 184.71170043945312), (261.8402404785156, 219.3214874267578), -29.780532836914062)\n",
      "[[ 808  344]\n",
      " [ 699  154]\n",
      " [ 926   24]\n",
      " [1035  214]]\n",
      "x1= 693 y1= 37 x2= 960 y2= 337\n",
      "serialid= 23\n",
      "contours= 2\n",
      "rect= ((865.7166748046875, 185.67404174804688), (263.0810546875, 218.72598266601562), -29.816997528076172)\n",
      "[[ 805  345]\n",
      " [ 697  156]\n",
      " [ 925   25]\n",
      " [1034  215]]\n",
      "x1= 694 y1= 33 x2= 960 y2= 333\n",
      "serialid= 24\n",
      "contours= 2\n",
      "rect= ((863.5706787109375, 185.32931518554688), (263.0980224609375, 218.35284423828125), -29.85429573059082)\n",
      "[[ 803  345]\n",
      " [ 695  156]\n",
      " [ 923   25]\n",
      " [1032  214]]\n",
      "x1= 699 y1= 38 x2= 960 y2= 329\n",
      "serialid= 25\n",
      "contours= 2\n",
      "rect= ((860.3525390625, 186.4324951171875), (262.0837097167969, 218.62864685058594), -29.670032501220703)\n",
      "[[ 800  346]\n",
      " [ 692  156]\n",
      " [ 920   26]\n",
      " [1028  216]]\n",
      "x1= 696 y1= 40 x2= 960 y2= 320\n",
      "serialid= 26\n",
      "contours= 2\n",
      "rect= ((858.50341796875, 186.5986785888672), (262.199951171875, 218.97894287109375), -29.854291915893555)\n",
      "[[ 799  346]\n",
      " [ 690  156]\n",
      " [ 917   26]\n",
      " [1026  216]]\n",
      "x1= 692 y1= 40 x2= 960 y2= 323\n",
      "serialid= 27\n",
      "contours= 2\n",
      "rect= ((857.3275146484375, 186.75), (262.2298278808594, 218.22027587890625), -30.31889533996582)\n",
      "[[ 799  347]\n",
      " [ 689  158]\n",
      " [ 915   26]\n",
      " [1025  214]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1= 688 y1= 35 x2= 960 y2= 332\n",
      "serialid= 28\n",
      "contours= 2\n",
      "rect= ((855.2703247070312, 186.93377685546875), (260.7844543457031, 217.3940887451172), -30.214509963989258)\n",
      "[[ 797  346]\n",
      " [ 687  158]\n",
      " [ 913   27]\n",
      " [1022  215]]\n",
      "x1= 682 y1= 36 x2= 960 y2= 330\n",
      "serialid= 29\n",
      "contours= 2\n",
      "rect= ((852.4915771484375, 187.0761260986328), (260.97894287109375, 219.01681518554688), -29.49746322631836)\n",
      "[[ 792  346]\n",
      " [ 684  156]\n",
      " [ 912   27]\n",
      " [1019  218]]\n",
      "x1= 678 y1= 37 x2= 958 y2= 340\n",
      "serialid= 30\n",
      "contours= 2\n",
      "rect= ((851.4603271484375, 187.22149658203125), (263.5667419433594, 219.49569702148438), -29.64250946044922)\n",
      "[[ 791  347]\n",
      " [ 682  157]\n",
      " [ 911   26]\n",
      " [1020  217]]\n",
      "x1= 684 y1= 35 x2= 960 y2= 332\n",
      "serialid= 31\n",
      "contours= 2\n",
      "rect= ((849.6243286132812, 187.86776733398438), (262.8334045410156, 219.80738830566406), -29.779146194458008)\n",
      "[[ 790  348]\n",
      " [ 680  157]\n",
      " [ 909   27]\n",
      " [1018  217]]\n",
      "x1= 700 y1= 32 x2= 960 y2= 329\n",
      "serialid= 32\n",
      "contours= 2\n",
      "rect= ((849.7338256835938, 186.84764099121094), (260.3734436035156, 218.40774536132812), -30.52340316772461)\n",
      "[[ 793  347]\n",
      " [ 682  158]\n",
      " [ 906   26]\n",
      " [1017  214]]\n",
      "x1= 674 y1= 38 x2= 959 y2= 335\n",
      "serialid= 33\n",
      "contours= 2\n",
      "rect= ((847.005615234375, 188.34295654296875), (261.98779296875, 218.54527282714844), -29.981639862060547)\n",
      "[[ 788  348]\n",
      " [ 678  159]\n",
      " [ 905   28]\n",
      " [1015  217]]\n",
      "x1= 675 y1= 38 x2= 956 y2= 337\n",
      "serialid= 34\n",
      "contours= 2\n",
      "rect= ((844.2846069335938, 188.12310791015625), (261.0931091308594, 217.30885314941406), -29.74488067626953)\n",
      "[[ 784  347]\n",
      " [ 677  158]\n",
      " [ 903   29]\n",
      " [1011  217]]\n",
      "x1= 671 y1= 38 x2= 960 y2= 334\n",
      "serialid= 35\n",
      "contours= 2\n",
      "rect= ((843.6732177734375, 188.40011596679688), (261.3548583984375, 218.04556274414062), -29.981639862060547)\n",
      "[[ 784  348]\n",
      " [ 676  159]\n",
      " [ 902   28]\n",
      " [1011  217]]\n",
      "x1= 672 y1= 37 x2= 956 y2= 340\n",
      "serialid= 36\n",
      "contours= 2\n",
      "rect= ((841.6900634765625, 188.89596557617188), (260.2511291503906, 217.32174682617188), -29.9456844329834)\n",
      "[[ 783  348]\n",
      " [ 674  159]\n",
      " [ 900   29]\n",
      " [1008  218]]\n",
      "x1= 670 y1= 38 x2= 954 y2= 339\n",
      "serialid= 37\n",
      "contours= 2\n",
      "rect= ((838.9323120117188, 188.56576538085938), (259.1130065917969, 218.224853515625), -29.81154441833496)\n",
      "[[ 780  347]\n",
      " [ 672  158]\n",
      " [ 897   29]\n",
      " [1005  218]]\n",
      "x1= 668 y1= 38 x2= 954 y2= 340\n",
      "serialid= 38\n",
      "contours= 2\n",
      "rect= ((836.0857543945312, 189.26614379882812), (259.2528381347656, 217.2425994873047), -29.44542694091797)\n",
      "[[ 776  347]\n",
      " [ 669  158]\n",
      " [ 895   30]\n",
      " [1002  220]]\n",
      "x1= 665 y1= 37 x2= 956 y2= 340\n",
      "serialid= 39\n",
      "contours= 2\n",
      "rect= ((833.9640502929688, 189.92550659179688), (259.89434814453125, 218.6504669189453), -29.341651916503906)\n",
      "[[ 774  348]\n",
      " [ 667  158]\n",
      " [ 893   30]\n",
      " [1000  221]]\n",
      "x1= 664 y1= 37 x2= 958 y2= 342\n",
      "serialid= 40\n",
      "contours= 2\n",
      "rect= ((837.1405029296875, 188.78990173339844), (259.85552978515625, 220.95034790039062), -29.948780059814453)\n",
      "[[ 779  349]\n",
      " [ 669  157]\n",
      " [ 894   28]\n",
      " [1004  219]]\n",
      "x1= 661 y1= 38 x2= 956 y2= 341\n",
      "serialid= 41\n",
      "contours= 2\n",
      "rect= ((834.6719360351562, 189.21023559570312), (260.21868896484375, 219.71792602539062), -30.11373519897461)\n",
      "[[ 777  349]\n",
      " [ 667  159]\n",
      " [ 892   28]\n",
      " [1002  218]]\n",
      "x1= 661 y1= 36 x2= 954 y2= 341\n",
      "serialid= 42\n",
      "contours= 2\n",
      "rect= ((832.1795654296875, 189.7645263671875), (259.9922790527344, 219.0439453125), -30.068584442138672)\n",
      "[[774 349]\n",
      " [664 160]\n",
      " [889  29]\n",
      " [999 219]]\n",
      "x1= 660 y1= 40 x2= 960 y2= 337\n",
      "serialid= 43\n",
      "contours= 2\n",
      "rect= ((831.5372314453125, 190.1361083984375), (259.7602844238281, 219.31857299804688), -29.913646697998047)\n",
      "[[773 349]\n",
      " [664 159]\n",
      " [889  30]\n",
      " [998 220]]\n",
      "x1= 660 y1= 38 x2= 951 y2= 342\n",
      "serialid= 44\n",
      "contours= 2\n",
      "rect= ((829.603515625, 190.31410217285156), (257.8096923828125, 219.83139038085938), -30.44862174987793)\n",
      "[[774 350]\n",
      " [662 160]\n",
      " [885  30]\n",
      " [996 219]]\n",
      "x1= 658 y1= 39 x2= 960 y2= 334\n",
      "serialid= 45\n",
      "contours= 2\n",
      "rect= ((826.9744262695312, 191.70037841796875), (258.9445495605469, 218.90145874023438), -30.430511474609375)\n",
      "[[770 351]\n",
      " [659 162]\n",
      " [883  31]\n",
      " [994 220]]\n",
      "x1= 656 y1= 39 x2= 953 y2= 342\n",
      "serialid= 46\n",
      "contours= 2\n",
      "rect= ((825.6017456054688, 191.72621154785156), (257.8848876953125, 220.89907836914062), -30.329082489013672)\n",
      "[[770 352]\n",
      " [658 161]\n",
      " [881  31]\n",
      " [992 221]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 650 y1= 38 x2= 952 y2= 342\n",
      "serialid= 47\n",
      "contours= 2\n",
      "rect= ((822.06591796875, 191.42889404296875), (257.5408630371094, 222.34225463867188), -29.827085494995117)\n",
      "[[765 351]\n",
      " [655 159]\n",
      " [878  30]\n",
      " [989 223]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 641 y1= 33 x2= 952 y2= 345\n",
      "serialid= 48\n",
      "contours= 2\n",
      "rect= ((816.0933837890625, 190.67462158203125), (261.1073913574219, 221.96932983398438), -31.22633934020996)\n",
      "[[761 353]\n",
      " [646 163]\n",
      " [870  28]\n",
      " [985 217]]\n",
      "x1= 640 y1= 35 x2= 950 y2= 341\n",
      "serialid= 49\n",
      "contours= 2\n",
      "rect= ((813.817138671875, 191.38815307617188), (257.9919738769531, 220.17523193359375), -30.388202667236328)\n",
      "[[758 351]\n",
      " [646 161]\n",
      " [869  31]\n",
      " [980 221]]\n",
      "x1= 639 y1= 35 x2= 954 y2= 342\n",
      "serialid= 50\n",
      "contours= 2\n",
      "rect= ((811.8163452148438, 191.35842895507812), (257.36309814453125, 221.7873992919922), -30.18653678894043)\n",
      "[[756 351]\n",
      " [644 160]\n",
      " [867  30]\n",
      " [978 222]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 645 y1= 29 x2= 954 y2= 344\n",
      "serialid= 51\n",
      "contours= 2\n",
      "rect= ((807.3550415039062, 191.53762817382812), (256.9261169433594, 225.4873809814453), -29.90593910217285)\n",
      "[[752 353]\n",
      " [639 157]\n",
      " [862  29]\n",
      " [974 225]]\n",
      "x1= 641 y1= 27 x2= 952 y2= 343\n",
      "serialid= 52\n",
      "contours= 2\n",
      "rect= ((805.8240966796875, 191.56283569335938), (257.297119140625, 223.1282958984375), -30.448623657226562)\n",
      "[[751 352]\n",
      " [638 160]\n",
      " [860  30]\n",
      " [973 222]]\n",
      "x1= 634 y1= 30 x2= 944 y2= 346\n",
      "serialid= 53\n",
      "contours= 2\n",
      "rect= ((804.8529052734375, 190.08819580078125), (261.0208435058594, 223.6341552734375), -30.963754653930664)\n",
      "[[750 353]\n",
      " [635 161]\n",
      " [859  27]\n",
      " [974 218]]\n",
      "x1= 632 y1= 31 x2= 943 y2= 347\n",
      "serialid= 54\n",
      "contours= 2\n",
      "rect= ((803.2302856445312, 190.43429565429688), (263.450439453125, 222.7846221923828), -31.304122924804688)\n",
      "[[748 354]\n",
      " [632 163]\n",
      " [857  26]\n",
      " [973 217]]\n",
      "x1= 630 y1= 31 x2= 942 y2= 347\n",
      "serialid= 55\n",
      "contours= 2\n",
      "rect= ((800.444580078125, 189.67559814453125), (261.9263610839844, 223.1194610595703), -31.304122924804688)\n",
      "[[746 353]\n",
      " [630 162]\n",
      " [854  26]\n",
      " [970 216]]\n",
      "x1= 636 y1= 30 x2= 945 y2= 341\n",
      "serialid= 56\n",
      "contours= 2\n",
      "rect= ((799.0794677734375, 189.97462463378906), (263.0153503417969, 222.24310302734375), -31.75948143005371)\n",
      "[[745 353]\n",
      " [628 164]\n",
      " [852  26]\n",
      " [969 215]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 629 y1= 28 x2= 938 y2= 343\n",
      "serialid= 57\n",
      "contours= 2\n",
      "rect= ((792.7839965820312, 189.8328857421875), (259.9999084472656, 224.50851440429688), -30.465543746948242)\n",
      "[[737 352]\n",
      " [623 158]\n",
      " [847  27]\n",
      " [961 220]]\n",
      "x1= 628 y1= 26 x2= 938 y2= 343\n",
      "serialid= 58\n",
      "contours= 2\n",
      "rect= ((790.6064453125, 190.1416473388672), (261.6042785644531, 224.3105010986328), -30.5792293548584)\n",
      "[[735 353]\n",
      " [620 160]\n",
      " [846  27]\n",
      " [960 220]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 590 y1= 30 x2= 902 y2= 342\n",
      "serialid= 59\n",
      "contours= 2\n",
      "rect= ((750.735107421875, 191.25918579101562), (262.07073974609375, 222.9128875732422), -31.65127182006836)\n",
      "[[697 354]\n",
      " [580 165]\n",
      " [803  27]\n",
      " [920 217]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 530 y1= 35 x2= 849 y2= 329\n",
      "serialid= 60\n",
      "contours= 2\n",
      "rect= ((693.5416259765625, 194.20376586914062), (266.53338623046875, 224.83294677734375), -35.122161865234375)\n",
      "[[649 362]\n",
      " [519 178]\n",
      " [737  25]\n",
      " [867 209]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 515 y1= 42 x2= 832 y2= 330\n",
      "serialid= 61\n",
      "contours= 2\n",
      "rect= ((676.86669921875, 195.70452880859375), (258.4964904785156, 222.74337768554688), -34.2868766784668)\n",
      "[[632 360]\n",
      " [507 176]\n",
      " [720  30]\n",
      " [846 214]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 505 y1= 45 x2= 823 y2= 325\n",
      "serialid= 62\n",
      "contours= 2\n",
      "rect= ((673.7996826171875, 194.35610961914062), (259.934814453125, 224.7327880859375), -34.07719421386719)\n",
      "[[629 360]\n",
      " [503 174]\n",
      " [718  28]\n",
      " [844 214]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 362 y1= 47 x2= 691 y2= 328\n",
      "serialid= 63\n",
      "contours= 2\n",
      "rect= ((535.0384521484375, 196.30767822265625), (255.43943786621094, 227.98178100585938), -33.690067291259766)\n",
      "[[492 362]\n",
      " [365 172]\n",
      " [578  30]\n",
      " [704 220]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 340 y1= 53 x2= 663 y2= 328\n",
      "serialid= 64\n",
      "contours= 2\n",
      "rect= ((503.19586181640625, 201.71505737304688), (259.4952392578125, 229.21234130859375), -33.95906066894531)\n",
      "[[459 369]\n",
      " [331 179]\n",
      " [546  34]\n",
      " [674 224]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 335 y1= 44 x2= 660 y2= 334\n",
      "serialid= 65\n",
      "contours= 2\n",
      "rect= ((498.72125244140625, 203.32382202148438), (259.36248779296875, 231.5657958984375), -34.346099853515625)\n",
      "[[456 372]\n",
      " [326 180]\n",
      " [540  34]\n",
      " [671 225]]\n",
      "x1= 324 y1= 52 x2= 659 y2= 327\n",
      "serialid= 66\n",
      "contours= 2\n",
      "rect= ((495.90509033203125, 204.4090576171875), (256.2507629394531, 227.8177032470703), -32.8190803527832)\n",
      "[[449 369]\n",
      " [326 178]\n",
      " [541  39]\n",
      " [665 230]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 94 y1= 4 x2= 137 y2= 15\n",
      "serialid= 67\n",
      "contours= 2\n",
      "rect= ((115.5, 9.5), (43.0, 11.0), -0.0)\n",
      "[[ 94  15]\n",
      " [ 94   4]\n",
      " [137   4]\n",
      " [137  15]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 328 y1= 59 x2= 649 y2= 337\n",
      "serialid= 68\n",
      "contours= 2\n",
      "rect= ((487.69232177734375, 205.9412078857422), (256.9654541015625, 226.171630859375), -33.78717803955078)\n",
      "[[443 371]\n",
      " [318 183]\n",
      " [531  40]\n",
      " [657 228]]\n",
      "x1= 316 y1= 59 x2= 644 y2= 335\n",
      "serialid= 69\n",
      "contours= 2\n",
      "rect= ((483.4306640625, 205.77398681640625), (260.7821044921875, 227.7397003173828), -33.401668548583984)\n",
      "[[437 372]\n",
      " [311 182]\n",
      " [529  38]\n",
      " [654 229]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 321 y1= 56 x2= 640 y2= 337\n",
      "serialid= 70\n",
      "contours= 2\n",
      "rect= ((479.86090087890625, 205.55487060546875), (257.50732421875, 227.0591278076172), -33.30228805541992)\n",
      "[[434 371]\n",
      " [309 181]\n",
      " [525  39]\n",
      " [649 229]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 313 y1= 48 x2= 637 y2= 345\n",
      "serialid= 71\n",
      "contours= 2\n",
      "rect= ((472.65386962890625, 207.15042114257812), (257.5823059082031, 229.65695190429688), -32.41703414916992)\n",
      "[[425 373]\n",
      " [302 179]\n",
      " [519  41]\n",
      " [642 235]]\n",
      "x1= 311 y1= 47 x2= 635 y2= 344\n",
      "serialid= 72\n",
      "contours= 2\n",
      "rect= ((470.9920654296875, 205.6641845703125), (258.69427490234375, 230.87899780273438), -32.77907943725586)\n",
      "[[424 372]\n",
      " [299 178]\n",
      " [517  38]\n",
      " [642 232]]\n",
      "x1= 95 y1= 5 x2= 134 y2= 15\n",
      "serialid= 73\n",
      "contours= 2\n",
      "rect= ((114.0, 9.5), (40.0, 11.0), -0.0)\n",
      "[[ 94  15]\n",
      " [ 94   4]\n",
      " [134   4]\n",
      " [134  15]]\n",
      "Traceback (most recent call last):\n",
      "  File \"process_video.py\", line 17, in <module>\n",
      "    results = model.detect([frame], verbose=0)\n",
      "  File \"/Volumes/G-DRIVE/cloud2019/Mask-RCNN-series/model.py\", line 2525, in detect\n",
      "    self.keras_model.predict([molded_images, image_metas, anchors], verbose=0)\n",
      "  File \"/Users/aadebuger/GEXT/maskrcnnvenv3/lib/python3.6/site-packages/keras/engine/training.py\", line 1169, in predict\n",
      "    steps=steps)\n",
      "  File \"/Users/aadebuger/GEXT/maskrcnnvenv3/lib/python3.6/site-packages/keras/engine/training_arrays.py\", line 294, in predict_loop\n",
      "    batch_outs = f(ins_batch)\n",
      "  File \"/Users/aadebuger/GEXT/maskrcnnvenv3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2715, in __call__\n",
      "    return self._call(inputs)\n",
      "  File \"/Users/aadebuger/GEXT/maskrcnnvenv3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2675, in _call\n",
      "    fetched = self._callable_fn(*array_vals)\n",
      "  File \"/Users/aadebuger/GEXT/maskrcnnvenv3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1439, in __call__\n",
      "    run_metadata_ptr)\n",
      "  File \"/Users/aadebuger/GEXT/maskrcnnvenv3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: indices[0] = 1 is not in [0, 1)\n",
      "\t [[{{node mrcnn_detection/map/while/GatherV2_2}} = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](mrcnn_detection/map/while/strided_slice, mrcnn_detection/map/while/non_max_suppression/NonMaxSuppressionV3, mrcnn_detection/map/while/PadV2/paddings/0/0)]]\n"
     ]
    }
   ],
   "source": [
    "!python process_video.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-09T13:33:57.300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                93\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "WARNING:tensorflow:From /Users/aadebuger/GEXT/maskrcnnvenv3/lib/python3.6/site-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "2019-02-09 21:34:07.235541: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n"
     ]
    }
   ],
   "source": [
    "!python process_video.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-09T15:07:07.686630Z",
     "start_time": "2019-02-09T13:52:43.496401Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                93\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           coco\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "WARNING:tensorflow:From /Users/aadebuger/GEXT/maskrcnnvenv3/lib/python3.6/site-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "2019-02-09 21:53:04.445794: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 926 y1= 89 x2= 960 y2= 199\n",
      "serialid= 0\n",
      "contours= 2\n",
      "rect= ((479.5, 271.5), (543.0, 959.0), -90.0)\n",
      "[[959 543]\n",
      " [  0 543]\n",
      " [  0   0]\n",
      " [959   0]]\n",
      "x1= 922 y1= 91 x2= 959 y2= 214\n",
      "serialid= 1\n",
      "contours= 2\n",
      "rect= ((940.5, 153.5), (37.0, 117.0), -0.0)\n",
      "[[922 212]\n",
      " [922  95]\n",
      " [959  95]\n",
      " [959 212]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 881 y1= 108 x2= 960 y2= 311\n",
      "serialid= 2\n",
      "contours= 2\n",
      "rect= ((479.5, 271.5), (543.0, 959.0), -90.0)\n",
      "[[959 543]\n",
      " [  0 543]\n",
      " [  0   0]\n",
      " [959   0]]\n",
      "x1= 877 y1= 110 x2= 960 y2= 317\n",
      "serialid= 3\n",
      "contours= 1\n",
      "x1= 873 y1= 107 x2= 960 y2= 320\n",
      "serialid= 4\n",
      "contours= 3\n",
      "x1= 867 y1= 107 x2= 960 y2= 321\n",
      "serialid= 5\n",
      "contours= 3\n",
      "x1= 868 y1= 109 x2= 960 y2= 324\n",
      "serialid= 6\n",
      "contours= 4\n",
      "x1= 866 y1= 108 x2= 960 y2= 324\n",
      "serialid= 7\n",
      "contours= 3\n",
      "x1= 865 y1= 108 x2= 960 y2= 324\n",
      "serialid= 8\n",
      "contours= 2\n",
      "rect= ((479.5, 271.5), (543.0, 959.0), -90.0)\n",
      "[[959 543]\n",
      " [  0 543]\n",
      " [  0   0]\n",
      " [959   0]]\n",
      "x1= 863 y1= 108 x2= 960 y2= 326\n",
      "serialid= 9\n",
      "contours= 2\n",
      "rect= ((479.5, 271.5), (543.0, 959.0), -90.0)\n",
      "[[959 543]\n",
      " [  0 543]\n",
      " [  0   0]\n",
      " [959   0]]\n",
      "x1= 863 y1= 108 x2= 960 y2= 329\n",
      "serialid= 10\n",
      "contours= 2\n",
      "rect= ((479.5, 271.5), (543.0, 959.0), -90.0)\n",
      "[[959 543]\n",
      " [  0 543]\n",
      " [  0   0]\n",
      " [959   0]]\n",
      "x1= 860 y1= 107 x2= 960 y2= 329\n",
      "serialid= 11\n",
      "contours= 2\n",
      "rect= ((479.5, 271.5), (543.0, 959.0), -90.0)\n",
      "[[959 543]\n",
      " [  0 543]\n",
      " [  0   0]\n",
      " [959   0]]\n",
      "x1= 858 y1= 109 x2= 960 y2= 329\n",
      "serialid= 12\n",
      "contours= 1\n",
      "x1= 856 y1= 110 x2= 960 y2= 329\n",
      "serialid= 13\n",
      "contours= 1\n",
      "x1= 853 y1= 110 x2= 960 y2= 330\n",
      "serialid= 14\n",
      "contours= 1\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 849 y1= 105 x2= 960 y2= 329\n",
      "serialid= 15\n",
      "contours= 1\n",
      "x1= 847 y1= 100 x2= 960 y2= 330\n",
      "serialid= 16\n",
      "contours= 1\n",
      "x1= 847 y1= 101 x2= 960 y2= 332\n",
      "serialid= 17\n",
      "contours= 1\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 844 y1= 100 x2= 960 y2= 322\n",
      "serialid= 18\n",
      "contours= 1\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 817 y1= 88 x2= 960 y2= 339\n",
      "serialid= 19\n",
      "contours= 1\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 707 y1= 38 x2= 960 y2= 324\n",
      "serialid= 20\n",
      "contours= 2\n",
      "rect= ((873.1661376953125, 184.27438354492188), (262.08538818359375, 218.52110290527344), -30.234573364257812)\n",
      "[[ 814  344]\n",
      " [ 704  155]\n",
      " [ 931   23]\n",
      " [1041  212]]\n",
      "x1= 710 y1= 35 x2= 960 y2= 330\n",
      "serialid= 21\n",
      "contours= 2\n",
      "rect= ((870.7179565429688, 184.30130004882812), (262.8225402832031, 217.86746215820312), -30.361719131469727)\n",
      "[[ 812  344]\n",
      " [ 702  156]\n",
      " [ 929   23]\n",
      " [1039  211]]\n",
      "x1= 695 y1= 36 x2= 960 y2= 335\n",
      "serialid= 22\n",
      "contours= 2\n",
      "rect= ((867.392822265625, 184.71170043945312), (261.8402404785156, 219.3214874267578), -29.780532836914062)\n",
      "[[ 808  344]\n",
      " [ 699  154]\n",
      " [ 926   24]\n",
      " [1035  214]]\n",
      "x1= 693 y1= 37 x2= 960 y2= 337\n",
      "serialid= 23\n",
      "contours= 2\n",
      "rect= ((865.7166748046875, 185.67404174804688), (263.0810546875, 218.72598266601562), -29.816997528076172)\n",
      "[[ 805  345]\n",
      " [ 697  156]\n",
      " [ 925   25]\n",
      " [1034  215]]\n",
      "x1= 694 y1= 33 x2= 960 y2= 333\n",
      "serialid= 24\n",
      "contours= 2\n",
      "rect= ((863.5706787109375, 185.32931518554688), (263.0980224609375, 218.35284423828125), -29.85429573059082)\n",
      "[[ 803  345]\n",
      " [ 695  156]\n",
      " [ 923   25]\n",
      " [1032  214]]\n",
      "x1= 699 y1= 38 x2= 960 y2= 329\n",
      "serialid= 25\n",
      "contours= 2\n",
      "rect= ((860.3525390625, 186.4324951171875), (262.0837097167969, 218.62864685058594), -29.670032501220703)\n",
      "[[ 800  346]\n",
      " [ 692  156]\n",
      " [ 920   26]\n",
      " [1028  216]]\n",
      "x1= 696 y1= 40 x2= 960 y2= 320\n",
      "serialid= 26\n",
      "contours= 2\n",
      "rect= ((858.50341796875, 186.5986785888672), (262.199951171875, 218.97894287109375), -29.854291915893555)\n",
      "[[ 799  346]\n",
      " [ 690  156]\n",
      " [ 917   26]\n",
      " [1026  216]]\n",
      "x1= 692 y1= 40 x2= 960 y2= 323\n",
      "serialid= 27\n",
      "contours= 2\n",
      "rect= ((857.3275146484375, 186.75), (262.2298278808594, 218.22027587890625), -30.31889533996582)\n",
      "[[ 799  347]\n",
      " [ 689  158]\n",
      " [ 915   26]\n",
      " [1025  214]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1= 688 y1= 35 x2= 960 y2= 332\n",
      "serialid= 28\n",
      "contours= 2\n",
      "rect= ((855.2703247070312, 186.93377685546875), (260.7844543457031, 217.3940887451172), -30.214509963989258)\n",
      "[[ 797  346]\n",
      " [ 687  158]\n",
      " [ 913   27]\n",
      " [1022  215]]\n",
      "x1= 682 y1= 36 x2= 960 y2= 330\n",
      "serialid= 29\n",
      "contours= 2\n",
      "rect= ((852.4915771484375, 187.0761260986328), (260.97894287109375, 219.01681518554688), -29.49746322631836)\n",
      "[[ 792  346]\n",
      " [ 684  156]\n",
      " [ 912   27]\n",
      " [1019  218]]\n",
      "x1= 678 y1= 37 x2= 958 y2= 340\n",
      "serialid= 30\n",
      "contours= 2\n",
      "rect= ((851.4603271484375, 187.22149658203125), (263.5667419433594, 219.49569702148438), -29.64250946044922)\n",
      "[[ 791  347]\n",
      " [ 682  157]\n",
      " [ 911   26]\n",
      " [1020  217]]\n",
      "x1= 684 y1= 35 x2= 960 y2= 332\n",
      "serialid= 31\n",
      "contours= 2\n",
      "rect= ((849.6243286132812, 187.86776733398438), (262.8334045410156, 219.80738830566406), -29.779146194458008)\n",
      "[[ 790  348]\n",
      " [ 680  157]\n",
      " [ 909   27]\n",
      " [1018  217]]\n",
      "x1= 700 y1= 32 x2= 960 y2= 329\n",
      "serialid= 32\n",
      "contours= 2\n",
      "rect= ((849.7338256835938, 186.84764099121094), (260.3734436035156, 218.40774536132812), -30.52340316772461)\n",
      "[[ 793  347]\n",
      " [ 682  158]\n",
      " [ 906   26]\n",
      " [1017  214]]\n",
      "x1= 674 y1= 38 x2= 959 y2= 335\n",
      "serialid= 33\n",
      "contours= 2\n",
      "rect= ((847.005615234375, 188.34295654296875), (261.98779296875, 218.54527282714844), -29.981639862060547)\n",
      "[[ 788  348]\n",
      " [ 678  159]\n",
      " [ 905   28]\n",
      " [1015  217]]\n",
      "x1= 675 y1= 38 x2= 956 y2= 337\n",
      "serialid= 34\n",
      "contours= 2\n",
      "rect= ((844.2846069335938, 188.12310791015625), (261.0931091308594, 217.30885314941406), -29.74488067626953)\n",
      "[[ 784  347]\n",
      " [ 677  158]\n",
      " [ 903   29]\n",
      " [1011  217]]\n",
      "x1= 671 y1= 38 x2= 960 y2= 334\n",
      "serialid= 35\n",
      "contours= 2\n",
      "rect= ((843.6732177734375, 188.40011596679688), (261.3548583984375, 218.04556274414062), -29.981639862060547)\n",
      "[[ 784  348]\n",
      " [ 676  159]\n",
      " [ 902   28]\n",
      " [1011  217]]\n",
      "x1= 672 y1= 37 x2= 956 y2= 340\n",
      "serialid= 36\n",
      "contours= 2\n",
      "rect= ((841.6900634765625, 188.89596557617188), (260.2511291503906, 217.32174682617188), -29.9456844329834)\n",
      "[[ 783  348]\n",
      " [ 674  159]\n",
      " [ 900   29]\n",
      " [1008  218]]\n",
      "x1= 670 y1= 38 x2= 954 y2= 339\n",
      "serialid= 37\n",
      "contours= 2\n",
      "rect= ((838.9323120117188, 188.56576538085938), (259.1130065917969, 218.224853515625), -29.81154441833496)\n",
      "[[ 780  347]\n",
      " [ 672  158]\n",
      " [ 897   29]\n",
      " [1005  218]]\n",
      "x1= 668 y1= 38 x2= 954 y2= 340\n",
      "serialid= 38\n",
      "contours= 2\n",
      "rect= ((836.0857543945312, 189.26614379882812), (259.2528381347656, 217.2425994873047), -29.44542694091797)\n",
      "[[ 776  347]\n",
      " [ 669  158]\n",
      " [ 895   30]\n",
      " [1002  220]]\n",
      "x1= 665 y1= 37 x2= 956 y2= 340\n",
      "serialid= 39\n",
      "contours= 2\n",
      "rect= ((833.9640502929688, 189.92550659179688), (259.89434814453125, 218.6504669189453), -29.341651916503906)\n",
      "[[ 774  348]\n",
      " [ 667  158]\n",
      " [ 893   30]\n",
      " [1000  221]]\n",
      "x1= 664 y1= 37 x2= 958 y2= 342\n",
      "serialid= 40\n",
      "contours= 2\n",
      "rect= ((837.1405029296875, 188.78990173339844), (259.85552978515625, 220.95034790039062), -29.948780059814453)\n",
      "[[ 779  349]\n",
      " [ 669  157]\n",
      " [ 894   28]\n",
      " [1004  219]]\n",
      "x1= 661 y1= 38 x2= 956 y2= 341\n",
      "serialid= 41\n",
      "contours= 2\n",
      "rect= ((834.6719360351562, 189.21023559570312), (260.21868896484375, 219.71792602539062), -30.11373519897461)\n",
      "[[ 777  349]\n",
      " [ 667  159]\n",
      " [ 892   28]\n",
      " [1002  218]]\n",
      "x1= 661 y1= 36 x2= 954 y2= 341\n",
      "serialid= 42\n",
      "contours= 2\n",
      "rect= ((832.1795654296875, 189.7645263671875), (259.9922790527344, 219.0439453125), -30.068584442138672)\n",
      "[[774 349]\n",
      " [664 160]\n",
      " [889  29]\n",
      " [999 219]]\n",
      "x1= 660 y1= 40 x2= 960 y2= 337\n",
      "serialid= 43\n",
      "contours= 2\n",
      "rect= ((831.5372314453125, 190.1361083984375), (259.7602844238281, 219.31857299804688), -29.913646697998047)\n",
      "[[773 349]\n",
      " [664 159]\n",
      " [889  30]\n",
      " [998 220]]\n",
      "x1= 660 y1= 38 x2= 951 y2= 342\n",
      "serialid= 44\n",
      "contours= 2\n",
      "rect= ((829.603515625, 190.31410217285156), (257.8096923828125, 219.83139038085938), -30.44862174987793)\n",
      "[[774 350]\n",
      " [662 160]\n",
      " [885  30]\n",
      " [996 219]]\n",
      "x1= 658 y1= 39 x2= 960 y2= 334\n",
      "serialid= 45\n",
      "contours= 2\n",
      "rect= ((826.9744262695312, 191.70037841796875), (258.9445495605469, 218.90145874023438), -30.430511474609375)\n",
      "[[770 351]\n",
      " [659 162]\n",
      " [883  31]\n",
      " [994 220]]\n",
      "x1= 656 y1= 39 x2= 953 y2= 342\n",
      "serialid= 46\n",
      "contours= 2\n",
      "rect= ((825.6017456054688, 191.72621154785156), (257.8848876953125, 220.89907836914062), -30.329082489013672)\n",
      "[[770 352]\n",
      " [658 161]\n",
      " [881  31]\n",
      " [992 221]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 650 y1= 38 x2= 952 y2= 342\n",
      "serialid= 47\n",
      "contours= 2\n",
      "rect= ((822.06591796875, 191.42889404296875), (257.5408630371094, 222.34225463867188), -29.827085494995117)\n",
      "[[765 351]\n",
      " [655 159]\n",
      " [878  30]\n",
      " [989 223]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 641 y1= 33 x2= 952 y2= 345\n",
      "serialid= 48\n",
      "contours= 2\n",
      "rect= ((816.0933837890625, 190.67462158203125), (261.1073913574219, 221.96932983398438), -31.22633934020996)\n",
      "[[761 353]\n",
      " [646 163]\n",
      " [870  28]\n",
      " [985 217]]\n",
      "x1= 640 y1= 35 x2= 950 y2= 341\n",
      "serialid= 49\n",
      "contours= 2\n",
      "rect= ((813.817138671875, 191.38815307617188), (257.9919738769531, 220.17523193359375), -30.388202667236328)\n",
      "[[758 351]\n",
      " [646 161]\n",
      " [869  31]\n",
      " [980 221]]\n",
      "x1= 639 y1= 35 x2= 954 y2= 342\n",
      "serialid= 50\n",
      "contours= 2\n",
      "rect= ((811.8163452148438, 191.35842895507812), (257.36309814453125, 221.7873992919922), -30.18653678894043)\n",
      "[[756 351]\n",
      " [644 160]\n",
      " [867  30]\n",
      " [978 222]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 645 y1= 29 x2= 954 y2= 344\n",
      "serialid= 51\n",
      "contours= 2\n",
      "rect= ((807.3550415039062, 191.53762817382812), (256.9261169433594, 225.4873809814453), -29.90593910217285)\n",
      "[[752 353]\n",
      " [639 157]\n",
      " [862  29]\n",
      " [974 225]]\n",
      "x1= 641 y1= 27 x2= 952 y2= 343\n",
      "serialid= 52\n",
      "contours= 2\n",
      "rect= ((805.8240966796875, 191.56283569335938), (257.297119140625, 223.1282958984375), -30.448623657226562)\n",
      "[[751 352]\n",
      " [638 160]\n",
      " [860  30]\n",
      " [973 222]]\n",
      "x1= 634 y1= 30 x2= 944 y2= 346\n",
      "serialid= 53\n",
      "contours= 2\n",
      "rect= ((804.8529052734375, 190.08819580078125), (261.0208435058594, 223.6341552734375), -30.963754653930664)\n",
      "[[750 353]\n",
      " [635 161]\n",
      " [859  27]\n",
      " [974 218]]\n",
      "x1= 632 y1= 31 x2= 943 y2= 347\n",
      "serialid= 54\n",
      "contours= 2\n",
      "rect= ((803.2302856445312, 190.43429565429688), (263.450439453125, 222.7846221923828), -31.304122924804688)\n",
      "[[748 354]\n",
      " [632 163]\n",
      " [857  26]\n",
      " [973 217]]\n",
      "x1= 630 y1= 31 x2= 942 y2= 347\n",
      "serialid= 55\n",
      "contours= 2\n",
      "rect= ((800.444580078125, 189.67559814453125), (261.9263610839844, 223.1194610595703), -31.304122924804688)\n",
      "[[746 353]\n",
      " [630 162]\n",
      " [854  26]\n",
      " [970 216]]\n",
      "x1= 636 y1= 30 x2= 945 y2= 341\n",
      "serialid= 56\n",
      "contours= 2\n",
      "rect= ((799.0794677734375, 189.97462463378906), (263.0153503417969, 222.24310302734375), -31.75948143005371)\n",
      "[[745 353]\n",
      " [628 164]\n",
      " [852  26]\n",
      " [969 215]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 629 y1= 28 x2= 938 y2= 343\n",
      "serialid= 57\n",
      "contours= 2\n",
      "rect= ((792.7839965820312, 189.8328857421875), (259.9999084472656, 224.50851440429688), -30.465543746948242)\n",
      "[[737 352]\n",
      " [623 158]\n",
      " [847  27]\n",
      " [961 220]]\n",
      "x1= 628 y1= 26 x2= 938 y2= 343\n",
      "serialid= 58\n",
      "contours= 2\n",
      "rect= ((790.6064453125, 190.1416473388672), (261.6042785644531, 224.3105010986328), -30.5792293548584)\n",
      "[[735 353]\n",
      " [620 160]\n",
      " [846  27]\n",
      " [960 220]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 590 y1= 30 x2= 902 y2= 342\n",
      "serialid= 59\n",
      "contours= 2\n",
      "rect= ((750.735107421875, 191.25918579101562), (262.07073974609375, 222.9128875732422), -31.65127182006836)\n",
      "[[697 354]\n",
      " [580 165]\n",
      " [803  27]\n",
      " [920 217]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 530 y1= 35 x2= 849 y2= 329\n",
      "serialid= 60\n",
      "contours= 2\n",
      "rect= ((693.5416259765625, 194.20376586914062), (266.53338623046875, 224.83294677734375), -35.122161865234375)\n",
      "[[649 362]\n",
      " [519 178]\n",
      " [737  25]\n",
      " [867 209]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 515 y1= 42 x2= 832 y2= 330\n",
      "serialid= 61\n",
      "contours= 2\n",
      "rect= ((676.86669921875, 195.70452880859375), (258.4964904785156, 222.74337768554688), -34.2868766784668)\n",
      "[[632 360]\n",
      " [507 176]\n",
      " [720  30]\n",
      " [846 214]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 505 y1= 45 x2= 823 y2= 325\n",
      "serialid= 62\n",
      "contours= 2\n",
      "rect= ((673.7996826171875, 194.35610961914062), (259.934814453125, 224.7327880859375), -34.07719421386719)\n",
      "[[629 360]\n",
      " [503 174]\n",
      " [718  28]\n",
      " [844 214]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 362 y1= 47 x2= 691 y2= 328\n",
      "serialid= 63\n",
      "contours= 2\n",
      "rect= ((535.0384521484375, 196.30767822265625), (255.43943786621094, 227.98178100585938), -33.690067291259766)\n",
      "[[492 362]\n",
      " [365 172]\n",
      " [578  30]\n",
      " [704 220]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 340 y1= 53 x2= 663 y2= 328\n",
      "serialid= 64\n",
      "contours= 2\n",
      "rect= ((503.19586181640625, 201.71505737304688), (259.4952392578125, 229.21234130859375), -33.95906066894531)\n",
      "[[459 369]\n",
      " [331 179]\n",
      " [546  34]\n",
      " [674 224]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 335 y1= 44 x2= 660 y2= 334\n",
      "serialid= 65\n",
      "contours= 2\n",
      "rect= ((498.72125244140625, 203.32382202148438), (259.36248779296875, 231.5657958984375), -34.346099853515625)\n",
      "[[456 372]\n",
      " [326 180]\n",
      " [540  34]\n",
      " [671 225]]\n",
      "x1= 324 y1= 52 x2= 659 y2= 327\n",
      "serialid= 66\n",
      "contours= 2\n",
      "rect= ((495.90509033203125, 204.4090576171875), (256.2507629394531, 227.8177032470703), -32.8190803527832)\n",
      "[[449 369]\n",
      " [326 178]\n",
      " [541  39]\n",
      " [665 230]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 94 y1= 4 x2= 137 y2= 15\n",
      "serialid= 67\n",
      "contours= 2\n",
      "rect= ((115.5, 9.5), (43.0, 11.0), -0.0)\n",
      "[[ 94  15]\n",
      " [ 94   4]\n",
      " [137   4]\n",
      " [137  15]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 328 y1= 59 x2= 649 y2= 337\n",
      "serialid= 68\n",
      "contours= 2\n",
      "rect= ((487.69232177734375, 205.9412078857422), (256.9654541015625, 226.171630859375), -33.78717803955078)\n",
      "[[443 371]\n",
      " [318 183]\n",
      " [531  40]\n",
      " [657 228]]\n",
      "x1= 316 y1= 59 x2= 644 y2= 335\n",
      "serialid= 69\n",
      "contours= 2\n",
      "rect= ((483.4306640625, 205.77398681640625), (260.7821044921875, 227.7397003173828), -33.401668548583984)\n",
      "[[437 372]\n",
      " [311 182]\n",
      " [529  38]\n",
      " [654 229]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 321 y1= 56 x2= 640 y2= 337\n",
      "serialid= 70\n",
      "contours= 2\n",
      "rect= ((479.86090087890625, 205.55487060546875), (257.50732421875, 227.0591278076172), -33.30228805541992)\n",
      "[[434 371]\n",
      " [309 181]\n",
      " [525  39]\n",
      " [649 229]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 313 y1= 48 x2= 637 y2= 345\n",
      "serialid= 71\n",
      "contours= 2\n",
      "rect= ((472.65386962890625, 207.15042114257812), (257.5823059082031, 229.65695190429688), -32.41703414916992)\n",
      "[[425 373]\n",
      " [302 179]\n",
      " [519  41]\n",
      " [642 235]]\n",
      "x1= 311 y1= 47 x2= 635 y2= 344\n",
      "serialid= 72\n",
      "contours= 2\n",
      "rect= ((470.9920654296875, 205.6641845703125), (258.69427490234375, 230.87899780273438), -32.77907943725586)\n",
      "[[424 372]\n",
      " [299 178]\n",
      " [517  38]\n",
      " [642 232]]\n",
      "x1= 95 y1= 5 x2= 134 y2= 15\n",
      "serialid= 73\n",
      "contours= 2\n",
      "rect= ((114.0, 9.5), (40.0, 11.0), -0.0)\n",
      "[[ 94  15]\n",
      " [ 94   4]\n",
      " [134   4]\n",
      " [134  15]]\n",
      "x1= 310 y1= 47 x2= 634 y2= 340\n",
      "serialid= 74\n",
      "contours= 2\n",
      "rect= ((469.780517578125, 205.29754638671875), (259.0955505371094, 229.30087280273438), -32.69198226928711)\n",
      "[[422 371]\n",
      " [298 178]\n",
      " [516  38]\n",
      " [640 231]]\n",
      "x1= 94 y1= 5 x2= 135 y2= 15\n",
      "serialid= 75\n",
      "contours= 2\n",
      "rect= ((114.0, 10.0), (42.0, 10.0), -0.0)\n",
      "[[ 93  15]\n",
      " [ 93   5]\n",
      " [135   5]\n",
      " [135  15]]\n",
      "x1= 308 y1= 45 x2= 630 y2= 339\n",
      "serialid= 76\n",
      "contours= 2\n",
      "rect= ((468.5953369140625, 205.822265625), (260.3941345214844, 230.32760620117188), -33.17851257324219)\n",
      "[[422 373]\n",
      " [296 180]\n",
      " [514  38]\n",
      " [640 230]]\n",
      "x1= 305 y1= 44 x2= 628 y2= 336\n",
      "serialid= 77\n",
      "contours= 2\n",
      "rect= ((466.74688720703125, 204.82177734375), (259.04571533203125, 229.92984008789062), -33.381473541259766)\n",
      "[[421 372]\n",
      " [295 180]\n",
      " [511  37]\n",
      " [638 229]]\n",
      "x1= 297 y1= 53 x2= 625 y2= 331\n",
      "serialid= 78\n",
      "contours= 2\n",
      "rect= ((464.6217346191406, 204.7465362548828), (257.75457763671875, 227.15460205078125), -33.490779876708984)\n",
      "[[419 370]\n",
      " [294 181]\n",
      " [509  38]\n",
      " [634 228]]\n",
      "x1= 300 y1= 47 x2= 625 y2= 336\n",
      "serialid= 79\n",
      "contours= 2\n",
      "rect= ((462.4317626953125, 205.26243591308594), (258.7586975097656, 228.49127197265625), -33.32121658325195)\n",
      "[[417 371]\n",
      " [291 180]\n",
      " [507  38]\n",
      " [633 229]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 283 y1= 53 x2= 619 y2= 331\n",
      "serialid= 80\n",
      "contours= 2\n",
      "rect= ((455.61724853515625, 203.565673828125), (258.4350891113281, 230.3439178466797), -32.993797302246094)\n",
      "[[409 370]\n",
      " [284 177]\n",
      " [501  36]\n",
      " [626 229]]\n",
      "x1= 283 y1= 52 x2= 615 y2= 327\n",
      "serialid= 81\n",
      "contours= 2\n",
      "rect= ((452.9273986816406, 202.78646850585938), (257.77435302734375, 228.38003540039062), -33.38851547241211)\n",
      "[[408 369]\n",
      " [282 178]\n",
      " [497  36]\n",
      " [623 227]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 286 y1= 44 x2= 611 y2= 340\n",
      "serialid= 82\n",
      "contours= 2\n",
      "rect= ((447.880859375, 203.46630859375), (254.64064025878906, 229.20277404785156), -33.29356384277344)\n",
      "[[404 369]\n",
      " [278 177]\n",
      " [491  37]\n",
      " [617 229]]\n",
      "x1= 280 y1= 45 x2= 609 y2= 335\n",
      "serialid= 83\n",
      "contours= 2\n",
      "rect= ((445.6219177246094, 202.65077209472656), (257.5483093261719, 228.6524200439453), -33.05582046508789)\n",
      "[[400 368]\n",
      " [275 177]\n",
      " [491  36]\n",
      " [615 228]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 275 y1= 43 x2= 603 y2= 333\n",
      "serialid= 84\n",
      "contours= 2\n",
      "rect= ((437.9206237792969, 203.58340454101562), (258.52764892578125, 230.31724548339844), -33.16635513305664)\n",
      "[[392 370]\n",
      " [266 177]\n",
      " [483  36]\n",
      " [609 229]]\n",
      "x1= 273 y1= 44 x2= 602 y2= 333\n",
      "serialid= 85\n",
      "contours= 2\n",
      "rect= ((436.1307373046875, 204.38668823242188), (257.9646911621094, 230.76486206054688), -33.381473541259766)\n",
      "[[391 371]\n",
      " [264 179]\n",
      " [480  37]\n",
      " [607 229]]\n",
      "x1= 270 y1= 45 x2= 597 y2= 332\n",
      "serialid= 86\n",
      "contours= 2\n",
      "rect= ((435.30767822265625, 203.46151733398438), (256.8262023925781, 229.09120178222656), -33.690067291259766)\n",
      "[[391 370]\n",
      " [264 179]\n",
      " [478  36]\n",
      " [605 227]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 263 y1= 45 x2= 587 y2= 335\n",
      "serialid= 87\n",
      "contours= 2\n",
      "rect= ((423.80963134765625, 201.21725463867188), (253.53578186035156, 229.42234802246094), -33.95109558105469)\n",
      "[[382 367]\n",
      " [254 176]\n",
      " [464  35]\n",
      " [593 225]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 257 y1= 43 x2= 580 y2= 335\n",
      "serialid= 88\n",
      "contours= 2\n",
      "rect= ((419.4549560546875, 202.5258026123047), (256.6312561035156, 230.21466064453125), -33.381473541259766)\n",
      "[[375 369]\n",
      " [248 177]\n",
      " [463  35]\n",
      " [589 228]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1= 258 y1= 46 x2= 583 y2= 335\n",
      "serialid= 89\n",
      "contours= 2\n",
      "rect= ((417.5, 202.99996948242188), (255.43946838378906, 229.6458740234375), -33.690067291259766)\n",
      "[[374 369]\n",
      " [247 178]\n",
      " [460  36]\n",
      " [587 227]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 245 y1= 45 x2= 572 y2= 339\n",
      "serialid= 90\n",
      "contours= 2\n",
      "rect= ((408.4075012207031, 205.28695678710938), (258.8579406738281, 231.14382934570312), -33.476280212402344)\n",
      "[[364 373]\n",
      " [236 180]\n",
      " [452  37]\n",
      " [580 230]]\n",
      "x1= 243 y1= 45 x2= 570 y2= 339\n",
      "serialid= 91\n",
      "contours= 2\n",
      "rect= ((407.01043701171875, 204.75486755371094), (259.7124938964844, 231.8864288330078), -34.066184997558594)\n",
      "[[364 373]\n",
      " [234 181]\n",
      " [449  35]\n",
      " [579 228]]\n",
      "x1= 239 y1= 54 x2= 568 y2= 331\n",
      "serialid= 92\n",
      "contours= 2\n",
      "rect= ((405.23162841796875, 205.04058837890625), (257.4589538574219, 229.8636474609375), -34.0609130859375)\n",
      "[[362 372]\n",
      " [234 181]\n",
      " [447  37]\n",
      " [576 228]]\n",
      "x1= 228 y1= 52 x2= 565 y2= 333\n",
      "serialid= 93\n",
      "contours= 2\n",
      "rect= ((400.826416015625, 205.53863525390625), (255.2766876220703, 230.21836853027344), -33.26142883300781)\n",
      "[[357 371]\n",
      " [230 179]\n",
      " [444  39]\n",
      " [570 231]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 230 y1= 44 x2= 557 y2= 337\n",
      "serialid= 94\n",
      "contours= 2\n",
      "rect= ((396.3077087402344, 204.4615478515625), (256.826171875, 231.3099822998047), -33.690067291259766)\n",
      "[[353 371]\n",
      " [225 179]\n",
      " [439  37]\n",
      " [567 229]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 224 y1= 43 x2= 552 y2= 339\n",
      "serialid= 95\n",
      "contours= 2\n",
      "rect= ((392.5409851074219, 204.835693359375), (257.6915283203125, 233.28927612304688), -33.28443908691406)\n",
      "[[348 373]\n",
      " [220 178]\n",
      " [436  36]\n",
      " [564 231]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 221 y1= 48 x2= 549 y2= 338\n",
      "serialid= 96\n",
      "contours= 2\n",
      "rect= ((388.69195556640625, 206.01731872558594), (258.2403259277344, 231.66346740722656), -33.32121658325195)\n",
      "[[344 373]\n",
      " [217 180]\n",
      " [432  38]\n",
      " [560 231]]\n",
      "x1= 219 y1= 47 x2= 547 y2= 336\n",
      "serialid= 97\n",
      "contours= 2\n",
      "rect= ((386.0447082519531, 206.33001708984375), (257.42437744140625, 232.4474334716797), -33.2748908996582)\n",
      "[[342 374]\n",
      " [214 179]\n",
      " [429  38]\n",
      " [557 232]]\n",
      "x1= 216 y1= 45 x2= 547 y2= 334\n",
      "serialid= 98\n",
      "contours= 2\n",
      "rect= ((383.3719482421875, 205.63381958007812), (257.7695007324219, 232.54579162597656), -32.96088790893555)\n",
      "[[338 373]\n",
      " [211 178]\n",
      " [428  37]\n",
      " [554 233]]\n",
      "NO INSTANCES TO DISPLAY\n",
      "x1= 212 y1= 46 x2= 539 y2= 338\n",
      "serialid= 99\n",
      "contours= 2\n",
      "rect= ((380.8030700683594, 205.20730590820312), (257.36419677734375, 233.2188720703125), -33.93649673461914)\n",
      "[[339 373]\n",
      " [208 180]\n",
      " [422  36]\n",
      " [552 230]]\n",
      "x1= 90 y1= 2 x2= 133 y2= 13\n",
      "serialid= 100\n",
      "contours= 2\n",
      "rect= ((111.0, 7.0), (42.0, 12.0), -0.0)\n",
      "[[ 90  13]\n",
      " [ 90   1]\n",
      " [132   1]\n",
      " [132  13]]\n",
      "x1= 209 y1= 45 x2= 536 y2= 339\n",
      "serialid= 101\n",
      "contours= 2\n",
      "rect= ((378.0821533203125, 205.13565063476562), (256.8065185546875, 232.2769317626953), -33.9297981262207)\n",
      "[[336 373]\n",
      " [206 180]\n",
      " [419  37]\n",
      " [549 229]]\n",
      "x1= 90 y1= 2 x2= 133 y2= 13\n",
      "serialid= 102\n",
      "contours= 2\n",
      "rect= ((111.0, 7.0), (42.0, 12.0), -0.0)\n",
      "[[ 90  13]\n",
      " [ 90   1]\n",
      " [132   1]\n",
      " [132  13]]\n",
      "2019-02-09 23:07:07.433489: F ./tensorflow/core/framework/tensor.h:663] Check failed: new_num_elements == NumElements() (2 vs. 3)\n"
     ]
    }
   ],
   "source": [
    "!python process_video.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
